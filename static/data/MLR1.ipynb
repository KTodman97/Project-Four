{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>State Name</th>\n",
       "      <th>State Abbreviation</th>\n",
       "      <th>State FIPS</th>\n",
       "      <th>Part D Prescribers</th>\n",
       "      <th>Urban Part D Prescribers</th>\n",
       "      <th>Rural Part D Prescribers</th>\n",
       "      <th>Part D Opioid Prescribers</th>\n",
       "      <th>Urban Part D Opioid Prescribers</th>\n",
       "      <th>Rural Part D Opioid Prescribers</th>\n",
       "      <th>...</th>\n",
       "      <th>Rural Long-Acting Opioid Claims</th>\n",
       "      <th>Overall Claims</th>\n",
       "      <th>Urban Overall Claims</th>\n",
       "      <th>Rural Overall Claims</th>\n",
       "      <th>Opioid Prescribing Rate</th>\n",
       "      <th>Urban Opioid Prescribing Rate</th>\n",
       "      <th>Rural Opioid Prescribing Rate</th>\n",
       "      <th>Long-Acting Opioid Prescribing Rate</th>\n",
       "      <th>Urban Long-Acting Opioid Prescribing Rate</th>\n",
       "      <th>Rural Long-Acting Opioid Prescribing Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12,821</td>\n",
       "      <td>10,888</td>\n",
       "      <td>1,927</td>\n",
       "      <td>7,418</td>\n",
       "      <td>6,087</td>\n",
       "      <td>1,327</td>\n",
       "      <td>...</td>\n",
       "      <td>42,494</td>\n",
       "      <td>29,157,450</td>\n",
       "      <td>21,627,302</td>\n",
       "      <td>7,505,293</td>\n",
       "      <td>7.74</td>\n",
       "      <td>7.85</td>\n",
       "      <td>7.41</td>\n",
       "      <td>9.60</td>\n",
       "      <td>10.25</td>\n",
       "      <td>7.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2,275</td>\n",
       "      <td>1,471</td>\n",
       "      <td>802</td>\n",
       "      <td>1,095</td>\n",
       "      <td>663</td>\n",
       "      <td>431</td>\n",
       "      <td>...</td>\n",
       "      <td>7,935</td>\n",
       "      <td>1,280,892</td>\n",
       "      <td>796,055</td>\n",
       "      <td>491,888</td>\n",
       "      <td>6.73</td>\n",
       "      <td>5.98</td>\n",
       "      <td>7.90</td>\n",
       "      <td>19.07</td>\n",
       "      <td>17.90</td>\n",
       "      <td>20.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>AZ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20,542</td>\n",
       "      <td>18,592</td>\n",
       "      <td>1,765</td>\n",
       "      <td>10,490</td>\n",
       "      <td>9,335</td>\n",
       "      <td>1,054</td>\n",
       "      <td>...</td>\n",
       "      <td>27,564</td>\n",
       "      <td>22,124,355</td>\n",
       "      <td>19,519,007</td>\n",
       "      <td>2,363,936</td>\n",
       "      <td>6.97</td>\n",
       "      <td>6.88</td>\n",
       "      <td>7.80</td>\n",
       "      <td>15.84</td>\n",
       "      <td>16.04</td>\n",
       "      <td>14.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7,909</td>\n",
       "      <td>5,849</td>\n",
       "      <td>2,051</td>\n",
       "      <td>4,698</td>\n",
       "      <td>3,263</td>\n",
       "      <td>1,431</td>\n",
       "      <td>...</td>\n",
       "      <td>30,958</td>\n",
       "      <td>16,757,632</td>\n",
       "      <td>9,807,375</td>\n",
       "      <td>6,934,818</td>\n",
       "      <td>6.73</td>\n",
       "      <td>7.01</td>\n",
       "      <td>6.32</td>\n",
       "      <td>9.18</td>\n",
       "      <td>10.52</td>\n",
       "      <td>7.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>6.0</td>\n",
       "      <td>109,563</td>\n",
       "      <td>105,164</td>\n",
       "      <td>4,360</td>\n",
       "      <td>49,623</td>\n",
       "      <td>47,069</td>\n",
       "      <td>2,533</td>\n",
       "      <td>...</td>\n",
       "      <td>83,520</td>\n",
       "      <td>131,842,337</td>\n",
       "      <td>125,176,022</td>\n",
       "      <td>6,625,783</td>\n",
       "      <td>5.47</td>\n",
       "      <td>5.32</td>\n",
       "      <td>8.31</td>\n",
       "      <td>11.61</td>\n",
       "      <td>11.32</td>\n",
       "      <td>15.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   State Name State Abbreviation  State FIPS Part D Prescribers  \\\n",
       "0  2013     Alabama                 AL          1.0             12,821   \n",
       "1  2013      Alaska                 AK          2.0              2,275   \n",
       "2  2013     Arizona                 AZ          4.0             20,542   \n",
       "3  2013    Arkansas                 AR          5.0              7,909   \n",
       "4  2013  California                 CA          6.0            109,563   \n",
       "\n",
       "  Urban Part D Prescribers Rural Part D Prescribers Part D Opioid Prescribers  \\\n",
       "0                   10,888                    1,927                     7,418   \n",
       "1                    1,471                      802                     1,095   \n",
       "2                   18,592                    1,765                    10,490   \n",
       "3                    5,849                    2,051                     4,698   \n",
       "4                  105,164                    4,360                    49,623   \n",
       "\n",
       "  Urban Part D Opioid Prescribers Rural Part D Opioid Prescribers  ...  \\\n",
       "0                           6,087                           1,327  ...   \n",
       "1                             663                             431  ...   \n",
       "2                           9,335                           1,054  ...   \n",
       "3                           3,263                           1,431  ...   \n",
       "4                          47,069                           2,533  ...   \n",
       "\n",
       "  Rural Long-Acting Opioid Claims Overall Claims Urban Overall Claims  \\\n",
       "0                          42,494     29,157,450           21,627,302   \n",
       "1                           7,935      1,280,892              796,055   \n",
       "2                          27,564     22,124,355           19,519,007   \n",
       "3                          30,958     16,757,632            9,807,375   \n",
       "4                          83,520    131,842,337          125,176,022   \n",
       "\n",
       "  Rural Overall Claims Opioid Prescribing Rate Urban Opioid Prescribing Rate  \\\n",
       "0            7,505,293                    7.74                          7.85   \n",
       "1              491,888                    6.73                          5.98   \n",
       "2            2,363,936                    6.97                          6.88   \n",
       "3            6,934,818                    6.73                          7.01   \n",
       "4            6,625,783                    5.47                          5.32   \n",
       "\n",
       "  Rural Opioid Prescribing Rate Long-Acting Opioid Prescribing Rate  \\\n",
       "0                          7.41                                9.60   \n",
       "1                          7.90                               19.07   \n",
       "2                          7.80                               15.84   \n",
       "3                          6.32                                9.18   \n",
       "4                          8.31                               11.61   \n",
       "\n",
       "  Urban Long-Acting Opioid Prescribing Rate  \\\n",
       "0                                     10.25   \n",
       "1                                     17.90   \n",
       "2                                     16.04   \n",
       "3                                     10.52   \n",
       "4                                     11.32   \n",
       "\n",
       "   Rural Long-Acting Opioid Prescribing Rate  \n",
       "0                                       7.64  \n",
       "1                                      20.41  \n",
       "2                                      14.95  \n",
       "3                                       7.06  \n",
       "4                                      15.17  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file into a pandas DataFrame\n",
    "data13 = pd.read_csv('mdOpioid_Prescribing_Geographic_2013.csv')\n",
    "data13.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data13.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data13.apply(lambda col:pd.to_numeric(col, errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data13 = data13.convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data13[\"Rural Part D Prescribers\"] = data13[\"Rural Part D Prescribers\"].str.replace('%','').astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data13.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data13[\"Rural Part D Opioid Prescribers\"] = pd.to_numeric(data13[\"Rural Part D Opioid Prescribers\"],errors='coerce')\n",
    "data13[\"Urban Part D Opioid Prescribers\"] = pd.to_numeric(data13[\"Urban Part D Opioid Prescribers\"],errors='coerce')\n",
    "data13[\"Urban Opioid Claims\"] = pd.to_numeric(data13[\"Urban Opioid Claims\"],errors='coerce')\n",
    "data13[\"Rural Opioid Claims\"] = pd.to_numeric(data13[\"Rural Opioid Claims\"],errors='coerce')\n",
    "data13[\"Year\"] = pd.to_numeric(data13[\"Year\"],errors='coerce')\n",
    "data13.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data13.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Reformat data\n",
    "data = data13.values\n",
    "X = data[:, 0:4]\n",
    "y = data[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y)\n",
    "encoded_y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class: 12,821\n",
      "Encoded Label: 4\n",
      "------------\n",
      "Original Class: 2,275\n",
      "Encoded Label: 15\n",
      "------------\n",
      "Original Class: 20,542\n",
      "Encoded Label: 18\n",
      "------------\n",
      "Original Class: 7,909\n",
      "Encoded Label: 47\n",
      "------------\n",
      "Original Class: 109,563\n",
      "Encoded Label: 3\n",
      "------------\n",
      "Original Class: 17,269\n",
      "Encoded Label: 10\n",
      "------------\n",
      "Original Class: 16,017\n",
      "Encoded Label: 9\n",
      "------------\n",
      "Original Class: 3,204\n",
      "Encoded Label: 26\n",
      "------------\n",
      "Original Class: 4,324\n",
      "Encoded Label: 32\n",
      "------------\n",
      "Original Class: 61,029\n",
      "Encoded Label: 44\n",
      "------------\n",
      "Original Class: 25,625\n",
      "Encoded Label: 23\n",
      "------------\n",
      "Original Class: 4,053\n",
      "Encoded Label: 31\n",
      "------------\n",
      "Original Class: 4,752\n",
      "Encoded Label: 34\n",
      "------------\n",
      "Original Class: 41,756\n",
      "Encoded Label: 36\n",
      "------------\n",
      "Original Class: 19,371\n",
      "Encoded Label: 11\n",
      "------------\n",
      "Original Class: 9,767\n",
      "Encoded Label: 51\n",
      "------------\n",
      "Original Class: 9,120\n",
      "Encoded Label: 50\n",
      "------------\n",
      "Original Class: 14,339\n",
      "Encoded Label: 6\n",
      "------------\n",
      "Original Class: 14,819\n",
      "Encoded Label: 7\n",
      "------------\n",
      "Original Class: 5,821\n",
      "Encoded Label: 38\n",
      "------------\n",
      "Original Class: 21,070\n",
      "Encoded Label: 19\n",
      "------------\n",
      "Original Class: 32,791\n",
      "Encoded Label: 29\n",
      "------------\n",
      "Original Class: 37,872\n",
      "Encoded Label: 30\n",
      "------------\n",
      "Original Class: 19,975\n",
      "Encoded Label: 14\n",
      "------------\n",
      "Original Class: 8,334\n",
      "Encoded Label: 48\n",
      "------------\n",
      "Original Class: 19,805\n",
      "Encoded Label: 13\n",
      "------------\n",
      "Original Class: 3,375\n",
      "Encoded Label: 27\n",
      "------------\n",
      "Original Class: 6,311\n",
      "Encoded Label: 40\n",
      "------------\n",
      "Original Class: 6,711\n",
      "Encoded Label: 41\n",
      "------------\n",
      "Original Class: 5,392\n",
      "Encoded Label: 37\n",
      "------------\n",
      "Original Class: 29,842\n",
      "Encoded Label: 24\n",
      "------------\n",
      "Original Class: 6,785\n",
      "Encoded Label: 43\n",
      "------------\n",
      "Original Class: 85,841\n",
      "Encoded Label: 49\n",
      "------------\n",
      "Original Class: 32,094\n",
      "Encoded Label: 28\n",
      "------------\n",
      "Original Class: 2,661\n",
      "Encoded Label: 17\n",
      "------------\n",
      "Original Class: 40,658\n",
      "Encoded Label: 35\n",
      "------------\n",
      "Original Class: 10,962\n",
      "Encoded Label: 2\n",
      "------------\n",
      "Original Class: 14,846\n",
      "Encoded Label: 8\n",
      "------------\n",
      "Original Class: 52,448\n",
      "Encoded Label: 39\n",
      "------------\n",
      "Original Class: 4,705\n",
      "Encoded Label: 33\n",
      "------------\n",
      "Original Class: 13,481\n",
      "Encoded Label: 5\n",
      "------------\n",
      "Original Class: 3,028\n",
      "Encoded Label: 25\n",
      "------------\n",
      "Original Class: 22,487\n",
      "Encoded Label: 20\n",
      "------------\n",
      "Original Class: 64,950\n",
      "Encoded Label: 45\n",
      "------------\n",
      "Original Class: 7,906\n",
      "Encoded Label: 46\n",
      "------------\n",
      "Original Class: 2,485\n",
      "Encoded Label: 16\n",
      "------------\n",
      "Original Class: 24,227\n",
      "Encoded Label: 22\n",
      "------------\n",
      "Original Class: 24,158\n",
      "Encoded Label: 21\n",
      "------------\n",
      "Original Class: 6,715\n",
      "Encoded Label: 42\n",
      "------------\n",
      "Original Class: 19,761\n",
      "Encoded Label: 12\n",
      "------------\n",
      "Original Class: 1,692\n",
      "Encoded Label: 1\n",
      "------------\n",
      "Original Class: 1,037,744\n",
      "Encoded Label: 0\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "for label, original_class in zip(encoded_y, y):\n",
    "    print('Original Class: ' + str(original_class))\n",
    "    print('Encoded Label: ' + str(label))\n",
    "    print('-' * 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Step 2: One-hot encoding\n",
    "one_hot_y = to_categorical(encoded_y)\n",
    "one_hot_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 4) (52, 1)\n"
     ]
    }
   ],
   "source": [
    "X = data13[[\"Urban Part D Prescribers\", \"Rural Part D Prescribers\", \"Urban Opioid Claims\", \"Rural Opioid Claims\"]]\n",
    "y = data13[\"Year\"].values.reshape(-1, 1)\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]\n",
      " [2013]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to create training and testing data\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urban Part D Prescribers    object\n",
      "Rural Part D Prescribers    object\n",
      "Urban Opioid Claims         object\n",
      "Rural Opioid Claims         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model using LinearRegression\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '15,575'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-307baa1eb026>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m### BEGIN SOLUTION\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtraining_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtesting_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[1;32m--> 492\u001b[1;33m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    756\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '15,575'"
     ]
    }
   ],
   "source": [
    "# Fit the model to the training data and calculate the scores for the training and testing data\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "model.fit(X_train, y_train)\n",
    "training_score = model.score(X_train, y_train)\n",
    "testing_score = model.score(X_test, y_test)\n",
    "\n",
    "### END SOLUTION \n",
    "\n",
    "print(f\"Training Score: {training_score}\")\n",
    "print(f\"Testing Score: {testing_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
